# CUDA 11.8 + cuDNN 8.x + full dev headers
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && \
    apt-get install -y --no-install-recommends python3 python3-pip && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# 1) PyTorch (still cu118 wheel, fully compatible)
RUN pip install --no-cache-dir --no-deps \
        torch==2.1.2+cu118 torchvision==0.16.2+cu118 torchaudio==2.1.2+cu118 \
        --extra-index-url https://download.pytorch.org/whl/cu118

# 2) CT2 3.24 + faster-whisper (both built against cuDNN 8)
RUN pip install --no-cache-dir --no-deps \
        ctranslate2==3.24.0 faster-whisper==0.9.0

# 3) Additional dependencies
RUN pip install --no-cache-dir soundfile numpy

# Create directory for models (will be cached)
RUN mkdir -p /app/models

# Copy our speech-to-text script
COPY speech_to_text_docker.py /app/speech_to_text_docker.py

# Create entrypoint script with diagnostic verification
RUN echo '#!/bin/bash\n\
echo "=== CUDA Diagnostic Verification ==="\n\
python3 -c "import torch, ctranslate2; print('"'"'Torch:''"'"', torch.cuda.is_available()); print('"'"'CT2  :'"'"', ctranslate2.get_cuda_device_count())"\n\
echo "==================================="\n\
\n\
if [ $# -eq 0 ]; then\n\
    echo "Usage: docker run --gpus all -v /path/to/audio:/audio whisper-gpu-cudnn8 /audio/file.wav"\n\
else\n\
    python3 /app/speech_to_text_docker.py "$@"\n\
fi' > /app/entrypoint.sh && chmod +x /app/entrypoint.sh

ENTRYPOINT ["/app/entrypoint.sh"]