# GPU-Accelerated Speech-to-Text For Ubuntu

A high-performance Python speech-to-text system that uses INSERT key recording and GPU-accelerated offline transcription with Faster Whisper models. Designed for Ubuntu systems with NVIDIA GPU support.

## Key Features

- ðŸš€ **GPU Acceleration**: 3.6x faster than CPU (RTX 4060: ~2.7s vs CPU: ~9.8s)
- ðŸŽ¯ **High Accuracy**: large-v3 Whisper model for best transcription quality  
- âŒ¨ï¸ **INSERT Key Trigger**: Simple hold-to-record, release-to-transcribe
- ðŸ”§ **No Sudo Required**: Uses pynput for X11 key listening
- ðŸ“ **Auto-typing**: Transcribed text automatically appears in active window
- ðŸ§ **Linux Optimized**: Tested on Ubuntu 24.04.2 LTS with CUDA 12.9

## Quick Demo

```bash
# 1. Start the system
./venv/bin/python3 src/key_listener.py

# 2. Hold INSERT key and speak: "Hello, this is a test"
# 3. Release INSERT key
# 4. See "Hello, this is a test" typed automatically (~2.7s later)
```

## System Requirements

- **OS**: Ubuntu 24.04+ (or compatible Linux with X11)
- **GPU**: NVIDIA GPU with CUDA 12.0+ support  
- **RAM**: 4GB+ (3GB VRAM for GPU model)
- **Python**: 3.10+
- **Audio**: Working microphone and `arecord` utility

## Installation

### 1. Clone and Setup

```bash
git clone https://github.com/CDNsun/speech-to-text-for-ubuntu
cd speech-to-text-for-ubuntu
```

### 2. Create Virtual Environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install Dependencies  

```bash
# Install locked dependencies (69 packages with exact versions)
pip install -r requirements.txt

# Install system audio tools
sudo apt install alsa-utils
```

### 4. Verify GPU Support

```bash
nvidia-smi  # Should show your GPU
python3 -c "import torch; print('CUDA available:', torch.cuda.is_available())"
```

## Usage

### Interactive Mode (Recommended)

Start the key listener for hands-free operation:

```bash
./venv/bin/python3 src/key_listener.py
```

**Controls:**
- **Hold INSERT key**: Start recording (you'll see logging activity)
- **Release INSERT key**: Stop recording and process with GPU
- **ESC key**: Exit the program

### Direct Processing

Test the GPU service with an audio file:

```bash
# Record a test file first
arecord -f cd -t wav -d 5 test.wav

# Process with GPU acceleration  
./scripts/run_gpu_speech.sh test.wav
```

## Performance

| Component | Time | Notes |
|-----------|------|--------|
| **GPU Model Loading** | ~2.0s | One-time per transcription |
| **GPU Transcription** | ~0.7s | For 5-second audio |
| **Total Processing** | ~2.7s | Complete pipeline |
| **CPU Fallback** | ~9.8s | Automatic if no GPU |

**Accuracy**: Excellent with large-v3 model (same quality as OpenAI's commercial service)

## Architecture

### Minimal Structure (8 Files)

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ gpu_service.py          # Main GPU-accelerated service  
â”‚   â””â”€â”€ key_listener.py         # INSERT key listener
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_gpu_speech.sh       # GPU environment wrapper
â”œâ”€â”€ requirements.txt            # Locked dependencies
â”œâ”€â”€ README.md                   # This file
â”œâ”€â”€ CLAUDE.md                   # Developer documentation
â”œâ”€â”€ ARCHITECTURE_ANALYSIS.md    # Technical analysis
â””â”€â”€ LICENSE.md                  # MIT License
```

### Processing Flow

```
INSERT Key â†’ pynput listener â†’ arecord â†’ GPU wrapper â†’ CUDA processing â†’ pyautogui typing
```

## Key Dependencies

- **faster-whisper==1.2.0**: Speech recognition engine
- **ctranslate2==4.6.0**: GPU acceleration backend
- **nvidia-cudnn-cu12==9.12.0.46**: CUDNN for GPU processing  
- **pynput==1.8.1**: X11 key listener (no sudo required)
- **pyautogui==0.9.54**: Automatic text typing

## Troubleshooting

### CUDNN Library Issues

If you see `"Unable to load libcudnn_ops.so.9.1.0"`:
- The system should auto-resolve this via the wrapper script
- Verify your virtual environment path in `scripts/run_gpu_speech.sh`
- Ensure CUDA 12.0+ is properly installed

### Key Listener Not Working

- Ensure you're running X11 (not Wayland): `echo $XDG_SESSION_TYPE`
- Virtual environment activated: `which python3` should show venv path
- pynput installed: `pip list | grep pynput`

### GPU Not Detected

- Check NVIDIA drivers: `nvidia-smi`
- Verify CUDA installation: `nvcc --version`
- System automatically falls back to CPU if GPU unavailable

### Audio Recording Issues

- Test microphone: `arecord -f cd -t wav -d 2 test.wav && aplay test.wav`
- Check audio permissions and device access
- Ensure `alsa-utils` is installed

## Auto-Start on Login

The system can automatically start the listener when you log in by adding it to your `.bashrc`:

```bash
# Start speech-to-text listener if not already running
if ! pgrep -f "src/key_listener.py" > /dev/null; then
    cd /home/sati/speech-to-text-for-ubuntu
    nohup ./venv/bin/python3 src/key_listener.py > /tmp/speech_listener.log 2>&1 &
    echo "Speech-to-text listener started"
fi
```

This code:
- âœ… Checks if listener is already running (prevents duplicates)
- âœ… Starts in background with `nohup` (survives logout)
- âœ… Logs output to `/tmp/speech_listener.log` for debugging
- âœ… Works with any terminal or SSH session

**Manual Controls:**
```bash
# Check if running
pgrep -f "src/key_listener.py"

# Stop listener
pkill -f "src/key_listener.py"

# View logs
tail -f /tmp/speech_listener.log
```

## Configuration

### Custom Key Binding

To change from INSERT key to another key, edit `src/key_listener.py`:

```python
# Line 97: Change keyboard.Key.insert to your preferred key
if key == keyboard.Key.f12:  # Example: Use F12 instead
```

### Model Selection

To use a different Whisper model, edit `src/gpu_service.py`:

```python
# Line 70: Change model size
model_size = "medium.en"  # Options: base.en, small.en, medium.en, large-v3
```

## Development

This codebase was refactored from 55+ files to 8 essential files for maintainability. 

**Key Points:**
- All original functionality preserved in git history
- Focus development on the 8 core files
- Run `tail -f /tmp/speech_to_text.log` to monitor processing
- Test changes with both direct calls and key listener integration

See `CLAUDE.md` for detailed development guidance.

## License

MIT License - see `LICENSE.md` for details.

## Performance History

This system was extensively optimized for both accuracy and speed:
- **Token optimization**: Reduced Claude correction costs by 99.8%  
- **GPU acceleration**: 3.6x speed improvement over CPU
- **CUDNN integration**: Resolved library compatibility issues
- **Minimal refactoring**: 85% file reduction while preserving functionality

See `ARCHITECTURE_ANALYSIS.md` for detailed technical analysis of the optimization process.

---

**ðŸŽ¯ Ready to use**: Hold INSERT, speak clearly, release INSERT, and watch your words appear!