#!/usr/bin/env python3
"""
Parallel Processing Speech-to-Text with Persistent Model Loading.
Optimizations: Model preloading, Claude session caching, pipeline overlap.
"""

import logging
import sys
import os
import subprocess
import time
import threading
import queue
from concurrent.futures import ThreadPoolExecutor, as_completed

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('/tmp/speech_to_text_parallel.log')
    ]
)

try:
    import numpy as np
    import pyautogui
    import soundfile as sf
    from faster_whisper import WhisperModel
except ImportError as e:
    print(f"Error: Required library not found: {e}")
    sys.exit(1)

class ParallelSpeechProcessor:
    def __init__(self):
        self.model = None
        self.model_load_time = 0
        self.claude_session_warm = False
        self.processing_queue = queue.Queue()
        self.executor = ThreadPoolExecutor(max_workers=3)
        
    def initialize_model(self):
        """Pre-load and cache the Whisper model"""
        if self.model is None:
            logging.info("üîß Initializing persistent Whisper base.en model...")
            start_time = time.time()
            self.model = WhisperModel("base.en", device="cpu", compute_type="int8")
            self.model_load_time = time.time() - start_time
            logging.info(f"‚úÖ Model cached in memory ({self.model_load_time:.2f}s)")
        else:
            logging.info("‚ö° Using cached model (0.00s)")
    
    def warm_claude_session(self):
        """Pre-warm Claude CLI session for faster responses"""
        if not self.claude_session_warm:
            logging.info("üî• Warming Claude CLI session...")
            try:
                # Send a quick test to establish session
                cmd = ['claude', '-c', '--model', 'haiku', 'Ready for speech correction tasks.']
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                if result.returncode == 0:
                    self.claude_session_warm = True
                    logging.info("‚úÖ Claude session warmed")
                else:
                    logging.warning("‚ö†Ô∏è Claude session warm-up failed")
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è Claude warm-up error: {e}")
    
    def transcribe_audio_fast(self, audio):
        """Fast transcription using cached model"""
        start_time = time.time()
        segments, _ = self.model.transcribe(
            audio, 
            language="en", 
            beam_size=1, 
            vad_filter=False
        )
        
        results = []
        for seg in segments:
            text = seg.text.strip()
            if text:
                results.append(text)
        
        transcribe_time = time.time() - start_time
        logging.info(f"‚ö° Fast transcription: {transcribe_time:.2f}s ({len(results)} segments)")
        return results
    
    def correct_with_claude_fast(self, raw_transcript):
        """Fast Claude correction using warm session"""
        try:
            correction_prompt = f"""The speech-to-text system produced this raw transcript:

"{raw_transcript}"

Based on our current conversation context, please provide the corrected version that makes sense and is grammatically correct. Consider:
- Common speech recognition errors (homophones, missing words, word boundaries)
- Technical terminology that might have been misrecognized  
- The conversational context of what we've been discussing
- Proper grammar and sentence structure

Please respond with ONLY the corrected transcript text, no explanations or quotes."""

            cmd = ['claude', '-c', '--model', 'haiku', correction_prompt]
            
            start_time = time.time()
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
            correction_time = time.time() - start_time
            
            if result.returncode == 0:
                corrected = result.stdout.strip()
                session_indicator = "üî•" if self.claude_session_warm else "üÜï"
                logging.info(f"{session_indicator} Fast correction: {correction_time:.2f}s")
                return corrected
            else:
                logging.error(f"Claude correction failed: {result.stderr}")
                return raw_transcript
                
        except subprocess.TimeoutExpired:
            logging.error("Claude correction timed out")
            return raw_transcript
        except Exception as e:
            logging.error(f"Claude correction error: {e}")
            return raw_transcript
    
    def parallel_process_audio(self, audio_file):
        """Main parallel processing pipeline"""
        session_start = time.time()
        
        # Step 1: Load audio (always needed first)
        logging.info("üìÇ Loading audio...")
        audio = self.load_audio(audio_file)
        
        # Step 2: Submit parallel tasks
        transcribe_future = self.executor.submit(self.transcribe_with_cached_model, audio)
        warmup_future = self.executor.submit(self.warm_claude_session)
        
        # Step 3: Get transcription result
        raw_transcript = transcribe_future.result()
        
        # Step 4: Ensure Claude is warmed (should be done by now)
        warmup_future.result()
        
        # Step 5: Submit correction task
        correction_future = self.executor.submit(self.correct_with_claude_fast, raw_transcript)
        
        # Step 6: Get final result
        corrected_transcript = correction_future.result()
        
        total_time = time.time() - session_start
        
        return raw_transcript, corrected_transcript, total_time
    
    def transcribe_with_cached_model(self, audio):
        """Transcription wrapper that ensures model is initialized"""
        self.initialize_model()
        return ' '.join(self.transcribe_audio_fast(audio))
    
    def load_audio(self, file_path):
        """Load and preprocess audio file"""
        if not os.path.exists(file_path):
            logging.error(f"Audio file not found: {file_path}")
            return None
        
        try:
            audio, samplerate = sf.read(file_path)
            audio = audio.astype('float32')
            
            if len(audio.shape) > 1 and audio.shape[1] > 1:
                audio = np.mean(audio, axis=1)
            
            duration = len(audio) / samplerate
            logging.info(f"üìÇ Audio loaded: {duration:.2f}s duration")
            return audio
            
        except Exception as e:
            logging.error(f"Failed to read audio file: {e}")
            return None
    
    def type_text(self, text):
        """Type text using pyautogui"""
        try:
            logging.info(f"‚å®Ô∏è Typing: {text}")
            pyautogui.typewrite(text + ' ')
        except Exception as e:
            logging.error(f"Failed to type: {e}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python speech_to_text_parallel.py <audio_file>")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    
    print("=" * 80)
    print("üöÄ PARALLEL PROCESSING SPEECH-TO-TEXT")
    print("=" * 80)
    
    # Initialize processor
    processor = ParallelSpeechProcessor()
    
    # Process with parallel optimizations
    raw_transcript, corrected_transcript, total_time = processor.parallel_process_audio(audio_file)
    
    if raw_transcript and corrected_transcript:
        print(f"\nüìù RAW TRANSCRIPT (base.en cached):")
        print(f"   '{raw_transcript}'")
        
        print(f"\n‚ú® CORRECTED TRANSCRIPT (Claude cached session):")
        print(f"   '{corrected_transcript}'")
        
        print(f"\nüìä PERFORMANCE ANALYSIS:")
        print(f"   Total time:     {total_time:.2f}s")
        print(f"   Same text:      {'Yes' if raw_transcript == corrected_transcript else 'No'}")
        print(f"   Char diff:      {len(corrected_transcript) - len(raw_transcript):+d}")
        print(f"   Speed gain:     {'~5-7s faster than sequential' if total_time < 7 else 'Similar to sequential'}")
        
        # Type result
        processor.type_text(corrected_transcript)
        
    print("=" * 80)
    
    # Cleanup
    processor.executor.shutdown(wait=True)

if __name__ == "__main__":
    main()