#!/usr/bin/env python3
"""
Test script for Session-Based Persistent Daemon
Tests the new session-based approach vs original approaches
"""

import subprocess
import time
import logging
import sys
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')

def test_session_daemon():
    """Test the session-based persistent daemon"""
    
    print("=" * 80)
    print("üß™ TESTING: Session-Based Persistent Daemon")
    print("=" * 80)
    
    # Test if we can import and run the daemon
    try:
        sys.path.append('/home/sati/speech-to-text-for-ubuntu')
        from speech_daemon import SpeechDaemon
        
        print("\nüöÄ Creating daemon instance...")
        daemon = SpeechDaemon()
        
        print("\nüîß Testing model initialization...")
        daemon.initialize_model()
        print(f"‚úÖ Whisper model loaded: {daemon.model is not None}")
        
        print("\nüéØ Testing session-based Claude warming...")
        success = daemon.warm_claude_session()
        print(f"‚úÖ Session warming: {'Success' if success else 'Failed'}")
        
        if daemon.session_established:
            print(f"üé© Session ID: {daemon.claude_session_id}")
            print(f"üìù Context summary length: {len(daemon.session_context_summary) if daemon.session_context_summary else 0} chars")
        
        # Create test audio file (or use existing one)
        test_audio_files = [
            "/tmp/recorded_audio.wav",
            "/home/sati/speech-to-text-for-ubuntu/test_audio.wav"
        ]
        
        test_audio = None
        for audio_file in test_audio_files:
            if os.path.exists(audio_file):
                test_audio = audio_file
                break
        
        if test_audio:
            print(f"\nüéµ Testing audio processing with: {test_audio}")
            result = daemon.process_audio_request(test_audio)
            
            if result:
                print("\nüìä PROCESSING RESULT:")
                print(f"   Raw transcript: '{result['raw']}'")
                print(f"   Corrected: '{result['corrected']}'") 
                print(f"   Confidence: {result['confidence']:.3f}")
                print(f"   Path used: {result['path']}")
                print(f"   Total time: {result['total_time']:.2f}s")
                print(f"   Transcribe time: {result['transcribe_time']:.2f}s")
                print(f"   Correction time: {result['correction_time']:.2f}s")
            else:
                print("‚ùå Audio processing failed")
        else:
            print("‚ö†Ô∏è No test audio file found - skipping audio processing test")
        
        # Get daemon stats
        stats = daemon.get_stats()
        print(f"\nüìà DAEMON STATISTICS:")
        print(f"   Processed: {stats['processed']}")
        print(f"   Session-based corrections: {stats['session_based_path']}")
        print(f"   Limited context corrections: {stats['limited_context_path']}")
        print(f"   Fast path: {stats['fast_path']}")
        print(f"   Session established: {stats['session_established']}")
        print(f"   Session ID: {stats['session_id']}")
        print(f"   Startup tokens used: {stats['session_startup_tokens']:,}")
        print(f"   Total tokens saved: {stats['total_tokens_saved']:,}")
        print(f"   Optimization: {stats['optimization']}")
        
        # Cleanup
        daemon.cleanup_claude_session()
        print("\n‚úÖ Test completed successfully!")
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        import traceback
        traceback.print_exc()

def compare_approaches():
    """Compare session-based vs traditional approaches"""
    
    print("\n" + "=" * 80)
    print("üìä APPROACH COMPARISON")
    print("=" * 80)
    
    approaches = [
        {
            "name": "Current Parallel Processing", 
            "description": "Model caching + full context (-c flag)",
            "tokens_per_correction": 284000,
            "startup_time": "2-3s (cold model)",
            "accuracy": "High (full context)"
        },
        {
            "name": "Limited Context", 
            "description": "Model caching + 3 exchanges",
            "tokens_per_correction": 650,
            "startup_time": "2-3s (cold model)", 
            "accuracy": "Poor (technical terms)"
        },
        {
            "name": "Session-Based Daemon",
            "description": "Persistent model + session context",
            "tokens_per_correction": 100,
            "startup_time": "<1s (warm model)",
            "accuracy": "High (workspace context)"
        }
    ]
    
    print(f"{'Approach':<25} {'Tokens/Correction':<20} {'Startup':<20} {'Accuracy':<25}")
    print("-" * 90)
    
    for approach in approaches:
        tokens = f"{approach['tokens_per_correction']:,}" if approach['tokens_per_correction'] >= 1000 else str(approach['tokens_per_correction'])
        print(f"{approach['name']:<25} {tokens:<20} {approach['startup_time']:<20} {approach['accuracy']:<25}")
    
    print("\nüéØ SESSION-BASED ADVANTAGES:")
    print("  ‚úÖ One-time context capture (284k tokens at startup)")
    print("  ‚úÖ Persistent Whisper model (sub-second transcription)")
    print("  ‚úÖ Persistent Claude session (~100 tokens per correction)")
    print("  ‚úÖ Technical terminology accuracy (workspace context)")
    print("  ‚úÖ 99.96% token reduction per correction (284k ‚Üí 100)")
    
    cost_per_1000_tokens = 1.2  # $1.20 per 1000 tokens for Haiku
    
    print("\nüí∞ COST COMPARISON (100 corrections):")
    for approach in approaches:
        total_tokens = approach['tokens_per_correction'] * 100
        if approach['name'] == "Session-Based Daemon":
            total_tokens = 284000 + (100 * 100)  # Startup + per correction
        
        cost = (total_tokens / 1000) * cost_per_1000_tokens
        print(f"  {approach['name']}: {total_tokens:,} tokens = ${cost:.2f}")

if __name__ == "__main__":
    try:
        test_session_daemon()
        compare_approaches()
    except KeyboardInterrupt:
        print("\nTest interrupted by user")
    except Exception as e:
        print(f"Test failed: {e}")
        sys.exit(1)